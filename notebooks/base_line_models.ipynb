{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>83.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>27.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>74.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>70.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>19.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>41.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>80.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>33.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>35.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>70.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  71  10.1   3.2  1.3  3.2  39.6      0.1  0.5  21.9  0.6  0.7  83.7   0.1   \n",
       "1  78  27.8   8.5  3.6  7.4  48.5      0.5  1.6  32.8  0.8  1.1  74.1   1.2   \n",
       "2  52  15.4   4.5  1.8  3.6  49.5      0.0  0.0   0.0  1.0  1.4  70.3   1.2   \n",
       "3  82  19.6   7.4  3.1  7.3  41.9      0.0  0.3   4.3  1.2  1.5  80.6   0.6   \n",
       "4  75  33.5  11.5  4.4  9.5  45.9      0.1  0.2  35.7  2.7  3.8  70.1   2.5   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   0.9  0.9  1.7  0.5  0.1  0.7            1  \n",
       "1   5.0  6.2  1.2  1.0  1.4  0.7            1  \n",
       "2   2.1  3.3  0.3  0.2  0.6  1.0            1  \n",
       "3   1.4  2.0  3.9  1.0  0.3  1.7            1  \n",
       "4   4.9  7.4  1.0  0.8  1.4  1.4            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "train = pd.read_csv('/Users/abdessamadbaahmed/Desktop/livrable_mp_data/data/nba_logreg_train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features and target\n",
    "X_train = train.drop('TARGET_5Yrs', axis=1)\n",
    "y_train = train['TARGET_5Yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/10 21:01:18 INFO mlflow.tracking.fluent: Experiment with name 'nba-investment-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/983841073769587609', creation_time=1673380878226, experiment_id='983841073769587609', last_update_time=1673380878226, lifecycle_stage='active', name='nba-investment-experiment', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the experiment \n",
    "mlflow.set_tracking_uri(\"http://20.224.70.229:5000/\")\n",
    "mlflow.set_experiment(\"nba-investment-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 983841073769587609\n",
      "Experiment name: nba-investment-experiment\n",
      "Experiment ID: 358522257770436896\n",
      "Experiment name: nba-investment-experiment_cv\n"
     ]
    }
   ],
   "source": [
    "# initialize mlflow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Search for experiments\n",
    "experiments = client.search_experiments()\n",
    "\n",
    "# Print the experiment ID and name for each experiment\n",
    "for experiment in experiments:\n",
    "    print(f\"Experiment ID: {experiment.experiment_id}\")\n",
    "    print(f\"Experiment name: {experiment.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into train and validation sets using stratified sampling so that we can preserve the same distribution of the target variable in the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to DMatrix objects\n",
    "train_dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
    "validation_dmatrix = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Define the objective function for the hyperparameter optimization\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        # Set the model and the search space in the run metadata\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Train the XGBoost model using the specified hyperparameters\n",
    "        booster = xgb.train(\n",
    "            params=params, # Hyperparameters\n",
    "            dtrain=train_dmatrix, # Training data\n",
    "            num_boost_round=1000, # Train for 1000 rounds\n",
    "            evals=[(validation_dmatrix, 'validation')], # Evaluate on the validation data at each iteration of training \n",
    "            early_stopping_rounds=50 # Stop training if the validation score does not improve for 50 rounds\n",
    "        )\n",
    "        \n",
    "        # Make predictions on the validation data\n",
    "        y_pred = booster.predict(validation_dmatrix).round()\n",
    "        \n",
    "        # Calculate the evaluation scores\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        \n",
    "        # Log the evaluation scores to MLFlow\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    return {'loss': 1 - precision, 'status': STATUS_OK} # Minimize the negative F1 score\n",
    "\n",
    "# Define the search space for the hyperparameters\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 200, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'binary:logistic',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "\n",
    "# Perform the hyperparameter optimization using the Tree Parzen Estimator algorithm\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.07098930409241866,\n",
       " 'max_depth': 100,\n",
       " 'min_child_weight': 3.7405054092622483,\n",
       " 'reg_alpha': 0.0195625946019779,\n",
       " 'reg_lambda': 0.03752422969172514,\n",
       " 'objective': 'binary:logistic',\n",
       " 'seed': 42}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result[\"max_depth\"] = int(best_result[\"max_depth\"])\n",
    "best_result[\"objective\"] = \"binary:logistic\"\n",
    "best_result[\"seed\"] = 42\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/10 21:38:04 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of xgboost. If you encounter errors during autologging, try upgrading / downgrading xgboost to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-logloss:0.68334\n",
      "[1]\tvalidation-logloss:0.67702\n",
      "[2]\tvalidation-logloss:0.66926\n",
      "[3]\tvalidation-logloss:0.66417\n",
      "[4]\tvalidation-logloss:0.65994\n",
      "[5]\tvalidation-logloss:0.65475\n",
      "[6]\tvalidation-logloss:0.65265\n",
      "[7]\tvalidation-logloss:0.65100\n",
      "[8]\tvalidation-logloss:0.64898\n",
      "[9]\tvalidation-logloss:0.65014\n",
      "[10]\tvalidation-logloss:0.64865\n",
      "[11]\tvalidation-logloss:0.64713\n",
      "[12]\tvalidation-logloss:0.64757\n",
      "[13]\tvalidation-logloss:0.65053\n",
      "[14]\tvalidation-logloss:0.65008\n",
      "[15]\tvalidation-logloss:0.64916\n",
      "[16]\tvalidation-logloss:0.65222\n",
      "[17]\tvalidation-logloss:0.64921\n",
      "[18]\tvalidation-logloss:0.65265\n",
      "[19]\tvalidation-logloss:0.65431\n",
      "[20]\tvalidation-logloss:0.65478\n",
      "[21]\tvalidation-logloss:0.65697\n",
      "[22]\tvalidation-logloss:0.65753\n",
      "[23]\tvalidation-logloss:0.65876\n",
      "[24]\tvalidation-logloss:0.65834\n",
      "[25]\tvalidation-logloss:0.66351\n",
      "[26]\tvalidation-logloss:0.66521\n",
      "[27]\tvalidation-logloss:0.66579\n",
      "[28]\tvalidation-logloss:0.66795\n",
      "[29]\tvalidation-logloss:0.66769\n",
      "[30]\tvalidation-logloss:0.66729\n",
      "[31]\tvalidation-logloss:0.66822\n",
      "[32]\tvalidation-logloss:0.67005\n",
      "[33]\tvalidation-logloss:0.67195\n",
      "[34]\tvalidation-logloss:0.67421\n",
      "[35]\tvalidation-logloss:0.67817\n",
      "[36]\tvalidation-logloss:0.68028\n",
      "[37]\tvalidation-logloss:0.68019\n",
      "[38]\tvalidation-logloss:0.68070\n",
      "[39]\tvalidation-logloss:0.68026\n",
      "[40]\tvalidation-logloss:0.68343\n",
      "[41]\tvalidation-logloss:0.68684\n",
      "[42]\tvalidation-logloss:0.68739\n",
      "[43]\tvalidation-logloss:0.68814\n",
      "[44]\tvalidation-logloss:0.68990\n",
      "[45]\tvalidation-logloss:0.68976\n",
      "[46]\tvalidation-logloss:0.69210\n",
      "[47]\tvalidation-logloss:0.69140\n",
      "[48]\tvalidation-logloss:0.68896\n",
      "[49]\tvalidation-logloss:0.69040\n",
      "[50]\tvalidation-logloss:0.69193\n",
      "[51]\tvalidation-logloss:0.69403\n",
      "[52]\tvalidation-logloss:0.69640\n",
      "[53]\tvalidation-logloss:0.69951\n",
      "[54]\tvalidation-logloss:0.69933\n",
      "[55]\tvalidation-logloss:0.70056\n",
      "[56]\tvalidation-logloss:0.70342\n",
      "[57]\tvalidation-logloss:0.70317\n",
      "[58]\tvalidation-logloss:0.70602\n",
      "[59]\tvalidation-logloss:0.70463\n",
      "[60]\tvalidation-logloss:0.70881\n",
      "[61]\tvalidation-logloss:0.71023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/10 21:38:05 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/abdessamadbaahmed/opt/anaconda3/envs/mlops_project/lib/python3.9/site-packages/mlflow/models/signature.py:130: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    }
   ],
   "source": [
    "# Enable automatic logging to MLFlow\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    booster = xgb.train(\n",
    "        params=best_result, # Hyperparameters\n",
    "        dtrain=train_dmatrix, # Training data\n",
    "        num_boost_round=1000, # Train for 1000 rounds\n",
    "        evals=[(validation_dmatrix, 'validation')], # Evaluate on the validation data at each iteration of training \n",
    "        early_stopping_rounds=50 # Stop training if the validation score does not improve for 50 rounds\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the objective function for the hyperparameter optimization\n",
    "def objective(params, X_train, y_train, k=5):\n",
    "\n",
    "    X_train = X_train.values\n",
    "    y_train = y_train.values\n",
    "\n",
    "    # Convert the data to DMatrix objects\n",
    "    train_dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Set the model and the search space in the run metadata\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Create a KFold object for cross-validation\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "        # Initialize the evaluation scores\n",
    "        accuracy = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        f1 = []\n",
    "\n",
    "        # Iterate over the folds\n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            # Split the data into training and validation sets\n",
    "            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "            # Convert the data to DMatrix objects\n",
    "            train_fold_dmatrix = xgb.DMatrix(X_train_fold, label=y_train_fold)\n",
    "            val_fold_dmatrix = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "\n",
    "            # Train the XGBoost model using the specified hyperparameters\n",
    "            booster = xgb.train(\n",
    "                params=params,\n",
    "                dtrain=train_fold_dmatrix,\n",
    "                num_boost_round=1000,\n",
    "                evals=[(val_fold_dmatrix, 'validation')],\n",
    "                early_stopping_rounds=50\n",
    "            ) \n",
    "            \n",
    "            # Make predictions on the validation data\n",
    "            y_pred = booster.predict(val_fold_dmatrix).round()\n",
    "\n",
    "            # Calculate the evaluation scores for the fold\n",
    "            accuracy.append(accuracy_score(y_val_fold, y_pred))\n",
    "            precision.append(precision_score(y_val_fold, y_pred))\n",
    "            recall.append(recall_score(y_val_fold, y_pred))\n",
    "            f1.append(f1_score(y_val_fold, y_pred))\n",
    "\n",
    "        # Calculate the mean evaluation scores over all the folds\n",
    "        mean_accuracy = np.mean(accuracy)\n",
    "        mean_precision = np.mean(precision)\n",
    "        mean_recall = np.mean(recall)\n",
    "        mean_f1 = np.mean(f1)\n",
    "        \n",
    "        # Log the evaluation scores to MLFlow\n",
    "        mlflow.log_metric(\"accuracy\", mean_accuracy)\n",
    "        mlflow.log_metric(\"precision\", mean_precision)\n",
    "        mlflow.log_metric(\"recall\", mean_recall)\n",
    "        mlflow.log_metric(\"f1_score\", mean_f1)\n",
    "\n",
    "    return {'loss': 1 - mean_f1, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for the hyperparameters\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'binary:logistic',\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "# Perform the hyperparameter optimization using the Tree Parzen Estimator algorithm\n",
    "def objective_cv(params):\n",
    "    return objective(k=5, X_train=X_train, y_train=y_train, params=params)\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective_cv,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('mlops_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3f808c4c48daa8be2dd2e709df5458392156827742a7efba711ccaf61034bb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
